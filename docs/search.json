[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jiayi He",
    "section": "",
    "text": "Here is the summary of me!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "My Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "blog/hw1.html",
    "href": "blog/hw1.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nDescription of the experiment: The experiment was designed to test whether offering a matching grant affects charitable giving. Karlan and List collaborated with a liberal nonprofit organization and sent fundraising letters to over 50,000 prior donors. These letters were randomly assigned to either a control group or a treatment group.\nThe control group received a standard fundraising letter. The treatment group received a nearly identical letter, except it included an announcement that a “concerned member” would match their donation. Within the treatment group, there were further randomizations: donors received different match ratios (1:1, 2:1, or 3:1), different maximum matching amounts ($25,000, $50,000, $100,000, or unspecified), and different suggested donation amounts (equal to, 1.25×, or 1.5× their previous highest contribution).\nThis design allows the authors to estimate both the overall effect of matching gifts and to test whether larger match ratios or different framing elements lead to higher donations. This project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1.html#introduction",
    "href": "blog/hw1.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nDescription of the experiment: The experiment was designed to test whether offering a matching grant affects charitable giving. Karlan and List collaborated with a liberal nonprofit organization and sent fundraising letters to over 50,000 prior donors. These letters were randomly assigned to either a control group or a treatment group.\nThe control group received a standard fundraising letter. The treatment group received a nearly identical letter, except it included an announcement that a “concerned member” would match their donation. Within the treatment group, there were further randomizations: donors received different match ratios (1:1, 2:1, or 3:1), different maximum matching amounts ($25,000, $50,000, $100,000, or unspecified), and different suggested donation amounts (equal to, 1.25×, or 1.5× their previous highest contribution).\nThis design allows the authors to estimate both the overall effect of matching gifts and to test whether larger match ratios or different framing elements lead to higher donations. This project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1.html#data",
    "href": "blog/hw1.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThe dataset contains 50,083 observations and 51 variables. Each observation corresponds to one prior donor who received a fundraising letter. Individuals were randomly assigned to a control group or a treatment group. Within the treatment group, they were further randomly assigned to different match ratios, match thresholds, and suggested donation amounts. Key variables include: - treatment: indicates if the donor received a matching gift offer (1 = yes, 0 = no) - ratio2, ratio3: dummies for match ratios of 2:1 and 3:1 (baseline is 1:1) - size25, size50, size100: dummies for match maximum amount - askd1, askd2, askd3: suggested donation amounts based on prior donation - amount: actual amount donated - gave: binary variable indicating whether the donor gave (1 = yes, 0 = no)\nWe will use these variables to replicate the results in Karlan and List (2007).\n\nlibrary(haven)\nlibrary(margins)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(knitr)\n\n\n\n\n\n\n\n\ndata &lt;- read_dta(\"karlan_list_2007.dta\")\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n#month since last donation \ntidy(t.test(mrm2 ~ treatment, data = data))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  -0.0137      13.0      13.0    -0.120   0.905    33394.   -0.238     0.211\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(lm(mrm2 ~ treatment, data = data))\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  13.0       0.0935   139.      0    \n2 treatment     0.0137    0.115      0.119   0.905\n\n# gender \ntidy(t.test(female ~ treatment, data = data))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter  conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  0.00755     0.283     0.275      1.75  0.0795    32451. -0.000889    0.0160\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(lm(female ~ treatment, data = data))\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  0.283     0.00350     80.7   0     \n2 treatment   -0.00755   0.00429     -1.76  0.0787\n\n# couple\ntidy(t.test(couple ~ treatment, data = data))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  0.00162    0.0930    0.0914     0.582   0.560    32439. -0.00383   0.00706\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(lm(couple ~ treatment, data = data))\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  0.0930    0.00226    41.1     0    \n2 treatment   -0.00162   0.00277    -0.584   0.559\n\n\n\n\nBalance Test Results\nTo evaluate whether the randomization successfully created comparable groups, we examine balance on several pre-treatment covariates: months since last donation (mrm2), gender (female), and couple status.\n\nFor months since last donation, the mean in the control group is 12.998 months and 13.012 months in the treatment group. The t-test yields a p-value of 0.9049, and the linear regression coefficient is not significant. This suggests no systematic difference between groups.\nFor gender, the control group has a female proportion of 28.3%, compared to 27.5% in the treatment group. The t-test gives a p-value of 0.0795. Although this is closer to significance, it is still above the 5% threshold, and the regression confirms no strong evidence of imbalance.\nFor couple status, the proportions are 9.30% (control) and 9.14% (treatment), with a p-value of 0.5604. No evidence suggests imbalance on this variable either.\n\nThese results confirm that the treatment assignment appears balanced across key demographic characteristics, supporting the validity of the experimental design."
  },
  {
    "objectID": "blog/hw1.html#experimental-results",
    "href": "blog/hw1.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Calculate donation rate by treatment group\ndonation_rate &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(response_rate = mean(gave == 1, na.rm = TRUE))\n\n# Rename group labels\ndonation_rate$treatment &lt;- factor(donation_rate$treatment, labels = c(\"Control\", \"Treatment\"))\n\n# Plot\nggplot(donation_rate, aes(x = treatment, y = response_rate)) +\n  geom_col(fill = \"steelblue\", width = 0.6) +\n  geom_text(aes(label = scales::percent(response_rate, accuracy = 0.1)), vjust = -0.5) +\n  ylim(0, max(donation_rate$response_rate) + 0.05) +\n  labs(\n    title = \"Proportion of Donors by Treatment Group\",\n    x = \"Group\",\n    y = \"Proportion Who Donated\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe bar plots display the donation response rate. For the control group, we have 1.8% of individual donated and for the treatment group, we have 2.2% of individuals donated. This suggests that individuals who received the matching donation offer were more likely to donate compared to those who did not.\n\ntidy(t.test(gave ~ treatment, data = data))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 -0.00418    0.0179    0.0220     -3.21 0.00133    36577. -0.00673  -0.00163\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(lm(gave ~ treatment, data = data))\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.0179    0.00110     16.2  4.78e-59\n2 treatment    0.00418   0.00135      3.10 1.93e- 3\n\n\nThe results show a statistically significant difference: individuals in the treatment group were more likely to donate than those in the control group. While the donation rates were low overall — roughly 1.8% in the control group versus 2.2% in the treatment group — the difference of about 0.4 percentage points is small but meaningful, and it is unlikely to have occurred by chance (p-value &lt; 0.01). This tells us something powerful about human behavior: even a subtle nudge, like telling people their donation will be matched, can influence their decision to give. People seem more willing to act charitably when they believe their contribution will have a greater impact. In this case, the match offer acted as a psychological motivator, reinforcing the value and urgency of giving.\n\ndata &lt;- data %&gt;%\n  mutate(treatment = ifelse(ratio &gt; 0, 1, 0))\n\n# Probit model\nprobit_model &lt;- glm(gave ~ treatment, family = binomial(link = \"probit\"), data = data)\n\ntidy(probit_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.10      0.0233    -90.1  0      \n2 treatment     0.0868    0.0279      3.11 0.00185\n\n\n\nmfx &lt;- margins(probit_model)\nsummary(mfx)\n\n    factor    AME     SE      z      p  lower  upper\n treatment 0.0043 0.0014 3.1044 0.0019 0.0016 0.0070\n\n\nThe estimated average marginal effect of the treatment assignment is approximately 0.0043, meaning that the presence of a matching offer increased the probability of donating by about 0.4 percentage points.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Filter treatment groups only\nmatch_data &lt;- data %&gt;%\n  filter(ratio %in% c(1, 2, 3)) %&gt;%\n  mutate(gave = ifelse(amount &gt; 0, 1, 0))\n\n# Split into groups\ngroup_1_1 &lt;- match_data %&gt;% filter(ratio == 1)\ngroup_2_1 &lt;- match_data %&gt;% filter(ratio == 2)\ngroup_3_1 &lt;- match_data %&gt;% filter(ratio == 3)\n\n# Run t-tests\nt_2_vs_1 &lt;- tidy(t.test(group_2_1$gave, group_1_1$gave))\nt_3_vs_1 &lt;- tidy(t.test(group_3_1$gave, group_1_1$gave))\n\nt_2_vs_1\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  0.00188    0.0226    0.0207     0.965   0.335    22225. -0.00194   0.00571\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\nt_3_vs_1\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1  0.00198    0.0227    0.0207      1.02   0.310    22215. -0.00185   0.00582\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\nNeither the $2:$1 nor the $3:$1 match rate significantly increases the probability of donation compared to the $1:$1 rate. This aligns with the authors’ interpretation on page 8 — that larger match ratios do not provide additional effectiveness. Our t-tests support this claim: p-values for both comparisons are well above conventional thresholds for statistical significance.\n\n# Use ratio1 as the base category\nmatch_data &lt;- match_data %&gt;%\n  mutate(\n    ratio2 = as.numeric(ratio == 2),\n    ratio3 = as.numeric(ratio == 3)\n  )\n\n# Regression using ratio2 and ratio3 (1:1 is base)\nmodel &lt;- glm(gave ~ ratio2 + ratio3, family = binomial(link = \"probit\"), data = match_data)\n\n# Show marginal effects\ntidy(margins(model))\n\n# A tibble: 2 × 5\n  term   estimate std.error statistic p.value\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 ratio2  0.00191   0.00198     0.965   0.335\n2 ratio3  0.00201   0.00198     1.01    0.310\n\n\nThe estimated marginal effect for the 2:1 match is 0.0019 with a p-value of 0.335. The estimated marginal effect for the 3:1 match is 0.0020 with a p-value of 0.310. These results are not statistically significant, indicating that neither the 2:1 nor the 3:1 match leads to a higher probability of giving compared to the 1:1 match.\n\n# Direct from data\nresponse_rates &lt;- match_data %&gt;%\n  group_by(ratio) %&gt;%\n  summarise(response_rate = mean(gave))\n\nrate_2_vs_1 &lt;- response_rates$response_rate[response_rates$ratio == 2] - \n               response_rates$response_rate[response_rates$ratio == 1]\n\nrate_3_vs_2 &lt;- response_rates$response_rate[response_rates$ratio == 3] - \n               response_rates$response_rate[response_rates$ratio == 2]\n\n# Run the probit model using ratio as a categorical variable\nmodel_factor &lt;- glm(gave ~ factor(ratio), family = binomial(link = \"probit\"), data = match_data)\n\nmfx &lt;- summary(margins(model_factor))\n\nmfx_diff_2_vs_1 &lt;- mfx$AME[mfx$factor == \"ratio2\"]\nmfx_diff_3_vs_2 &lt;- mfx$AME[mfx$factor == \"ratio3\"] - mfx$AME[mfx$factor == \"ratio2\"]\n\nlist(\n  direct_data_differences = list(\n    `2:1 vs 1:1` = rate_2_vs_1,\n    `3:1 vs 2:1` = rate_3_vs_2\n  ),\n  regression_marginal_effect_differences = list(\n    `2:1 vs 1:1` = mfx_diff_2_vs_1,\n    `3:1 vs 2:1` = mfx_diff_3_vs_2\n  )\n)\n\n$direct_data_differences\n$direct_data_differences$`2:1 vs 1:1`\n[1] 0.001884251\n\n$direct_data_differences$`3:1 vs 2:1`\n[1] 0.000100024\n\n\n$regression_marginal_effect_differences\n$regression_marginal_effect_differences$`2:1 vs 1:1`\n     ratio2 \n0.001884251 \n\n$regression_marginal_effect_differences$`3:1 vs 2:1`\n     ratio3 \n0.000100024 \n\n\nFrom both the raw data and the regression model, we find: - The difference in response rate between 2:1 and 1:1 is approximately 0.00188 (0.19 percentage points). - The difference in response rate between 3:1 and 2:1 is a mere 0.00010 (0.01 percentage points).\nThese values are extremely small, and consistent across both the direct calculation from raw data and the marginal effects estimated from the probit model. The response rate differences between 1:1, 2:1, and 3:1 match ratios are economically negligible and statistically insignificant. This strongly supports the conclusion drawn in Karlan and List (2007):\n&gt; “Larger match ratios—$3:$1 and $2:$1—relative to smaller match ratios ($1:$1) had no additional impact.” Increasing the match ratio beyond 1:1 does not improve donor response rates and may not be a cost-effective strategy for fundraisers.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ntidy(t.test(amount ~ treatment, data = data))\n\n# A tibble: 1 × 10\n  estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.154     0.813     0.967     -1.92  0.0551    36216.   -0.311   0.00334\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\ntidy(lm(amount ~ treatment, data = data))\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    0.813    0.0674     12.1  1.84e-33\n2 treatment      0.154    0.0826      1.86 6.28e- 2\n\n\nThe result from t-test, we have mean in control group is 0.81 and treatment group is 0.97, p-value is 0.055. The avg donation amount is slightly higher in the treatment group means that matching grants may slightly increase donation amounts but the main thing is to give people the incentive to give not on how much thet give.\n\n# Filter for donors only\ndonors_only &lt;- data %&gt;%\n  filter(amount &gt; 0)\n\n# Run OLS regression on positive donations\nmodel_conditional &lt;- lm(amount ~ treatment, data = donors_only)\n\ntidy(model_conditional)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    45.5       2.42    18.8   5.47e-68\n2 treatment      -1.67      2.87    -0.581 5.61e- 1\n\n\nFrom the output, the intercepts reflects the average donation amount in the control group. And the coefficient on treatment shows the average increase (or decrease) in donation amount among donors. This coefficient does not have a clear causal interpretation since we are limited the condition to gave =1 and the selection bias exists since the treatment may impact people who donates in the first place. Thus, this regression cannot identify the causal effect of treatment on donation size.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "blog/hw1.html#simulation-experiment",
    "href": "blog/hw1.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n\n\n\n\n\n\n\n\nThe simulation illustrates the Law of Large Numbers in action. Initially, the cumulative average of the simulated differences is noisy and jumps around, but as the number of draws increases, it converges steadily toward the true mean difference of 0.004.This demonstrates how, in repeated sampling, the sample average becomes a reliable estimator of the population average — the foundational idea behind statistical inference methods like the t-test used earlier in this blog.It reinforces why even small effects (like a 0.004 difference in donation likelihood) can be detected reliably with large samples.\n\n\nCentral Limit Theorem\n\n\n\n\n\n\n\n\n\nThis simulation illustrates the Central Limit Theorem using differences in simulated donation probabilities between treatment and control groups. - With a small sample size (n = 50), the sampling distribution of the difference in means is noisy and not very symmetric. - As the sample size increases (n = 200, 500, 1000), the distributions become tighter, smoother, and more centered around the true mean difference - In all cases, zero is near the center, not in the tail — suggesting no systematic bias in our estimator. This demonstrates why, in the real-world Karlan & List field experiment (with over 50,000 subjects!), we can reliably detect even small differences in donation behavior. The CLT ensures that the sampling distribution of the mean is approximately normal and centered, allowing valid statistical inference."
  }
]